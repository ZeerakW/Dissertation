\ifpdf
    \graphicspath{{Chapter9/Figs/Raster/}{Chapter9/Figs/PDF/}{Chapter9/Figs/}}
\else
    \graphicspath{{Chapter9/Figs/Vector/}{Chapter9/Figs/}}
\fi

\chapter{The Politics of Toxicity in Content Moderation Infrastructures}\label{chap:filter}

Throughout our process, we have worked with notions of ``toxicity'' and ``abuse'' without further examining their implications or the political constructs they live within. Here we then take a critical look at the implications of the political economies which these terms live within and how content moderation infrastructures define toxic content.

Through an examination of three content moderation tools, the Perspective API, Opt Out and our own abuse detection system from \autoref{chap:liwc}, we argue that content moderation's historical reliance on static categories, which are embedded in social systems of racism and patriarchy, embeds content moderation technoogies in structures that risk reproducing social inequalities. We choose the three technologies to illustrate the differences between top-down and bottom-up approaches to content moderation and the distinct ways in which they engage in embed meaning to ``toxic'' and ``abuse'', and the cultural filtering work that content moderation has come to do. These three examples enable to us identify the challenges inherent in attempts to automate and scale content moderation and ask two fundamental questions of content moderation: Whom are content moderation systems for and who gets to define and enforce them?

By engaging with scholarly work that draw on and develop pollution and discard theory, we can better understand this discourse of ``toxicity'' and identify new avenues of research for content moderation studies. Moreover, by relying on theories of social pollution from anthropology \cite{Douglas:1966} and work on dirt and toxicity in the field of discard studies \cite{Libeoiron:2018,Lepawsky:2019}, we argue that content moderation should move beyond the question of merely removal of toxic content to a productive 're-ordering of our environment' through practices of classification and purification \cite{Douglas:1966}.

\section{Content Moderation as a Problem of Dirt}
If we consider content moderation technologies as `protective' filtering systems that reject and accept to ensure the `health' of communities, then we must also reckon with their inseparability from discourses of hygiene and pollution. Following \cite{Lepawsky:2019}
